[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download My Resume (PDF)"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "üéì Education",
    "text": "üéì Education\n\nM.S. Data Science, Willamette University (Expected 2025)\n\nB.A. Mathematics (Applied Computer Science), Wells College\n\nB.A. Accounting (Auditing), Washington & Jefferson College\n\n150+ credit hours\n\nMinors: Computing & Information Studies, Professional Writing"
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "üß† Technical Skills",
    "text": "üß† Technical Skills\n\nLanguages: Python, R, SQL (Postgres, LITE, DuckDB), PowerShell, VBA\n\nQuant Research: Mean Reversion, Factor Modeling, Financial Modeling (Excel), Cointegration, GARCH, ARIMA, Monte Carlo\n\nInfrastructure: Docker, Grafana, Prometheus, Kafka, KDB+, alpaca-trade-api, Airflow, ClickHouse, AWS\n\nML Models: Regression Models, Neural Networks (MLPs, LSTMs), KNN, SVM, Naive Bayes\n\nVisualization: ggplot2, matplotlib, Shiny, Tableau, Power BI"
  },
  {
    "objectID": "resume.html#relevant-python-libraries",
    "href": "resume.html#relevant-python-libraries",
    "title": "Resume",
    "section": "üêç Relevant Python Libraries",
    "text": "üêç Relevant Python Libraries\n\nQuant: pandas, numpy, scipy, statsmodels, QuantLib, bt, backtrader, zipline, alphalens, quantstats, pyfolio\n\nML/Forecasting: scikit-learn, xgboost, keras, prophet, neuralprophet, statsmodels, h2o\n\nNLP & Alt Data: transformers, finbert, nltk, spacy, vaderSentiment, beautifulsoup4"
  },
  {
    "objectID": "resume.html#relevant-experience",
    "href": "resume.html#relevant-experience",
    "title": "Resume",
    "section": "üíº Relevant Experience",
    "text": "üíº Relevant Experience\nCFA Research Challenge\n- Co-authored equity research valuation report on Absci for the CFA Institute National Research Challenge\n- Built DCF, DuPont, and asset turnover models (Excel)\n- Modeled, forecasted, and visualized in R\nTechnology & Accounting Consulting Intern ‚Äì HPM Tech Services\n- Built and installed custom hardware/software to improve client performance\n- Provided remote cybersecurity and workflow support to clients\n- Diagnosed ticketing system bugs, saving the company hundreds in lost revenue"
  },
  {
    "objectID": "resume.html#excellence-competitions",
    "href": "resume.html#excellence-competitions",
    "title": "Resume",
    "section": "üèÜ Excellence & Competitions",
    "text": "üèÜ Excellence & Competitions\n\nNCAA D3 Baseball: Highest active winning percentage (.918) during tenure (2020‚Äì2023)\n\nRanked top-3 nationally in saves as high-leverage reliever (2024)\n\n1st Place: Elevator Pitch Competition\n\n2nd Place: Business Design Challenge"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Project Portfolio",
    "section": "",
    "text": "View Code \n\n\n This full-stack statistical arbitrage system supports live, historical, and simulated strategy testing. Deployed via a Dash UI, it tracks trades in real time, logs strategy-specific PnL, and overlays comparative performance plots. Designed for iterative research and execution refinement, the framework makes it easy to evaluate mean reversion, momentum, and rule-based strategies through a unified interface. \n\n\nTech Stack: Python, Dash, Pandas, Plotly"
  },
  {
    "objectID": "projects.html#statistical-arbitrage-systems",
    "href": "projects.html#statistical-arbitrage-systems",
    "title": "Project Portfolio",
    "section": "",
    "text": "View Code \n\n\n This full-stack statistical arbitrage system supports live, historical, and simulated strategy testing. Deployed via a Dash UI, it tracks trades in real time, logs strategy-specific PnL, and overlays comparative performance plots. Designed for iterative research and execution refinement, the framework makes it easy to evaluate mean reversion, momentum, and rule-based strategies through a unified interface. \n\n\nTech Stack: Python, Dash, Pandas, Plotly"
  },
  {
    "objectID": "projects.html#geo-spatial-latency-arbitrage",
    "href": "projects.html#geo-spatial-latency-arbitrage",
    "title": "Project Portfolio",
    "section": "Geo-Spatial Latency Arbitrage",
    "text": "Geo-Spatial Latency Arbitrage\n\n    View Code \n\n\n Quantisphere is a cloud-native, microservice-driven platform for latency arbitrage. It streams high-frequency market data via Kafka, stores it in Parquet (with optional kdb+ integration), and drives real-time signal generation through Python-based machine learning models. The global latency map and WebSocket dashboard visualize sub-millisecond cross-exchange spreads, while Prometheus and Grafana provide observability and alerts across the full stack. The system is designed for precision execution, scalability, and real-time optimization of arbitrage strategies. \n\n\nTech Stack: Docker, Kubernetes, Kafka, AWS, Python, Postgres, Prometheus, Grafana, WebSockets, Parquet, kdb+"
  },
  {
    "objectID": "projects.html#alternative-data-processing-methods",
    "href": "projects.html#alternative-data-processing-methods",
    "title": "Project Portfolio",
    "section": "Alternative Data Processing Methods",
    "text": "Alternative Data Processing Methods\n\n    View Code \n\n\n Processes SEC filings, earnings calls, and financial news using transformer-based NLP models, converting raw text into structured alpha-generating features. These are integrated into multifactor models for downstream strategy development and portfolio construction. \n\n\nTech Stack: Python, SEC EDGAR API, NLP, Pandas"
  },
  {
    "objectID": "projects.html#monte-carlo-garch-arima-other-forecasting-models",
    "href": "projects.html#monte-carlo-garch-arima-other-forecasting-models",
    "title": "Project Portfolio",
    "section": "Monte Carlo, GARCH, ARIMA & Other Forecasting Models",
    "text": "Monte Carlo, GARCH, ARIMA & Other Forecasting Models\n\n    View Code \n\n\n Forecasting engine combining Monte Carlo simulation with GARCH, ARIMA, and other time-series models. Built in R with ggplot2, it simulates equity price paths under stochastic volatility and visualizes probabilistic outcomes with confidence intervals to support forward-looking risk and return analysis. \n\n\nTech Stack: R, ggplot2, Monte Carlo Simulation, GARCH, ARIMA"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nQuant Dev Portfolio\n",
    "section": "",
    "text": "‚ÄúEngineering alpha through research-grade systematic infrastructure.‚Äù\n\n\n\n\n\n\nAreas of Focus\n\n\n\n\nMarket Data Pipelines\n\n\nStatistical Arbitrage (Equities, ETFs, Pairs)\n\n\nSystematic Options Strategy Backtesting\n\n\nReal-Time Market Manipulation Detection (Spoofing, Layering)\n\n\nLatency Arbitrage Routing Optimization\n\n\nMachine Learning for Signal Generation\n\n\n\n\n\n\n\n\nProfessional Summary\n\n\nQuantitative developer and systems engineer with a background in mathematics, accounting, and financial engineering. I design institutional-grade infrastructure for real-time data collection, anomaly detection, and latency-optimized execution. Passionate about building high-performance research systems with measurable edge.\n\n\n\n\n\n\nSystems in Action\n\n\n\nLII-MSI Pair: Custom research infrastructure and data pipeline for evaluating laddered, multi-leg statistical arbitrage strategies.\n\n\n\nSimulated PnL: 1375.99 ¬† | ¬† Sharpe: 3.29 (rolling: 3.09) ¬† | ¬† Trades: 104\n\n\n\n\n\n\n\nConnect With Me\n\n\nLinkedIn GitHub\n\n\n\n\n\n¬© 2025 Cameron Hayman ¬∑ Built with Quarto"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "",
    "text": "‚ÄúMy mission is to bridge quant theory with infrastructure engineering to deploy strategies that work in the real world.‚Äù\n\n\n\n\n\nAbout Me\n\n\nI‚Äôm a quantitative developer with a background in mathematics, accounting, and data science. I specialize in building production-grade infrastructure for real-time strategy research, anomaly detection, and latency-critical execution. I design and deploy end-to-end quant systems ‚Äî from data ingestion and feature engineering to cloud-native model deployment and interactive visualization. My focus is on delivering high-performance solutions that bridge research innovation with live trading environments ‚Äî turning alpha signals into executable strategies.\n\n\n\n\n\n\nAreas of Expertise\n\n\n\nData Engineering: Scalable pipelines (Python, SQL, APIs, Websockets, Docker)\n\n\nCloud Infrastructure: AWS, Railway, Docker, Kubernetes, GitHub Actions\n\n\nQuant Research: Strategy backtesting (Mean Reversion, Momentum, Options)\n\n\nMachine Learning: LSTMs, GARCH, Monte Carlo, NLP (SEC Filings, Tone)\n\n\nScientific Computing: NumPy, SciPy, parallelized research workflows\n\n\nRisk & Execution: HFT logic (Python, some C++), VaR modeling, portfolio construction\n\n\nVisualization: ggplot2 (R), Matplotlib (Python), interactive dashboards"
  },
  {
    "objectID": "msds-capstone.html",
    "href": "msds-capstone.html",
    "title": "MSDS Capstone:",
    "section": "",
    "text": "Goal: Real-time detection of spoofing and quote-stuffing using L2 market-book data."
  },
  {
    "objectID": "msds-capstone.html#tools-stack",
    "href": "msds-capstone.html#tools-stack",
    "title": "MSDS Capstone:",
    "section": "Tools & Stack",
    "text": "Tools & Stack\n\nReal-time WebSocket ingestion (IBKR/Alpaca)\n\nPostgreSQL + Parquet storage (AWS S3)\n\nXGBoost + Isolation Forest + Rule-based hybrid\n\nDocker deployment, Railway, AWS EC2, + Grafana Dashboard\n\n\n\n\nData Accumulation Overview\n\n\n\n\n\nResults\n\n\n\n\nDetected XX% of synthetic spoofing injections\n\n\nFalse positive rate under XX%\n\n\nBenchmarked against synthetic and historical NYSE data\n\n\n\nFully deployable, live detection system integrated with Alpaca and IBKR.\n\n\n\n\nüìÇ Read full report (to be posted upon completion in a few weeks!)\nüì´ Contact for interview case walkthrough"
  },
  {
    "objectID": "quantisphere.html",
    "href": "quantisphere.html",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "",
    "text": "Quantisphere is a hedge-fund-grade systematic trading architecture engineered for real-time execution, PnL optimization, and latency-sensitive arbitrage. It was built from the ground up to mirror professional HFT infrastructure."
  },
  {
    "objectID": "quantisphere.html#key-features",
    "href": "quantisphere.html#key-features",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "Key Features",
    "text": "Key Features\n\nMicrosecond-level latency routing using Neo4j path switching\n\nReal-time FIX gateway simulation\n\nGrafana dashboards with Prometheus metrics + alerts\n\nFull Dockerized deployment pipeline\n\nELK stack log aggregation and observability\n\nDeep Reinforcement Learning‚Äìbased strategy inference\n\n\nCustom-built to support sub-millisecond decision making in globally distributed markets."
  },
  {
    "objectID": "quantisphere.html#system-architecture",
    "href": "quantisphere.html#system-architecture",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "System Architecture",
    "text": "System Architecture\n\n\n\nSandbox Demo: Latency Optimization"
  },
  {
    "objectID": "quantisphere.html#architecture-highlights",
    "href": "quantisphere.html#architecture-highlights",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "Architecture Highlights",
    "text": "Architecture Highlights\n\nExecution Engine: Python + C++ hybrid for ultra-low-latency routing\n\nMutable Data Ingestion: IBKR & Alpaca APIs with dynamic failover logic\n\nML Inference: Deep RL engine driving trade selection & routing decisions\n\nMonitoring: Grafana + Prometheus with live metrics and Slack alerting\n\nBacktest Suite: Custom latency replay framework for path efficiency tests"
  },
  {
    "objectID": "quantisphere.html#links",
    "href": "quantisphere.html#links",
    "title": "Cameron Hayman | Quantitative Developer",
    "section": "Links",
    "text": "Links\n\nüìÇ View the full Quantisphere repo on GitHub\n\nüìù Contact for demo access or interview walkthrough"
  }
]